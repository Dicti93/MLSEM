{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP3tN6ArQMBaz7mhpmjzla",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dicti93/MLSEM/blob/master/5.%20Modelling/Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFsRq6ITWb3O"
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# scikit-learn imports for machine learning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# tensorflow for nn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results storage for confusion matrices, classification reports, and ROC curves\n",
        "confusion_matrices = []\n",
        "roc_curves = []\n",
        "classification_reports = []\n",
        "accuracy = []"
      ],
      "metadata": {
        "id": "gjlSZyxyWgeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variable into dummy/indicator variables (one-hot encoding)\n",
        "X = pd.get_dummies(features_cleaned)\n",
        "\n",
        "# Store feature names after one-hot encoding, as they will be needed for interpreting the model's feature importances\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# Assign the encoded diagnosis column to y, which serves as the target variable for the model\n",
        "y = diagnosis_cleaned['Diagnosis_encoded']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Ensure the same set of columns in both train and test sets\n",
        "# - 'join=left' ensures all columns in X_train are kept, aligning X_test to it\n",
        "# - 'axis=1' specifies that the alignment is to be done on columns\n",
        "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)"
      ],
      "metadata": {
        "id": "_tCXRvGOWgge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an imputer object that replaces NaN values with the median of the column\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "RBbNwGlaWgjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a RandomForestClassifier with a specified number of estimators and a fixed random state for reproducibility\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create a pipeline that first imputes missing values then trains a model\n",
        "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('classifier', rf_model)])\n",
        "\n",
        "# Fit the model using the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_rf = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "accuracy.append(accuracy_rf)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "confusion_matrices.append(cm_rf)\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
        "roc_curves.append((fpr_rf, tpr_rf))\n",
        "\n",
        "# Calculate classification report\n",
        "cls_report_rf = classification_report(y_test, y_pred_rf)\n",
        "classification_reports.append(cls_report_rf)\n",
        "\n",
        "# Print the accuracy and a classification report to see performance details\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"Confusion Matrix:\\n\", cm_rf)\n",
        "print(\"Classification Report:\\n\", cls_report_rf)"
      ],
      "metadata": {
        "id": "7gox25KjWglP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline that first imputes missing values then trains a model\n",
        "pipeline = Pipeline(steps=[('imputer', imputer), ('scaler', scaler), ('classifier', LogisticRegression(max_iter=1000, random_state=42))])\n",
        "\n",
        "# Fit the model on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_lr = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "confusion_matrices.append(cm_lr)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "accuracy.append(accuracy_lr)\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
        "roc_curves.append((fpr_lr, tpr_lr))\n",
        "\n",
        "# Calculate classification report\n",
        "cls_report_lr = classification_report(y_test, y_pred_lr)\n",
        "classification_reports.append(cls_report_lr)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"Confusion Matrix:\\n\", cm_lr)\n",
        "print(\"Classification Report:\\n\", cls_report_lr)"
      ],
      "metadata": {
        "id": "KCiei90XWgnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Gradient Boosting Classifier with current learning rate\n",
        "gbs_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
        "\n",
        "# Create and fit the pipeline\n",
        "gbs_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('classifier', gbs_model)\n",
        "])\n",
        "gbs_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_gbs = gbs_pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_gbs = accuracy_score(y_test, y_pred_gbs)\n",
        "accuracy.append(accuracy_gbs)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix_gbs = confusion_matrix(y_test, y_pred_gbs)\n",
        "confusion_matrices.append(conf_matrix_gbs)\n",
        "\n",
        "# Calculate ROC curve\n",
        "fpr_gbs, tpr_gbs, _ = roc_curve(y_test, gbs_pipeline.predict_proba(X_test)[:, 1])\n",
        "roc_curves.append((fpr_gbs, tpr_gbs))\n",
        "\n",
        "# Calculate classification report\n",
        "cls_report_gbs = classification_report(y_test, y_pred_gbs)\n",
        "classification_reports.append(cls_report_gbs)\n",
        "\n",
        "# Optionally print results for each model\n",
        "print(f\"Learning Rate: {0.05}\")\n",
        "print(f\"Accuracy: {accuracy_gbs}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix_gbs}\")\n",
        "print(f\"Classification Report:\\n{cls_report_gbs}\\n\")"
      ],
      "metadata": {
        "id": "jWTiXc4oWgpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a range of learning rates with 0.1 steps between 0 and 1\n",
        "learning_rates = np.arange(0.1, 1, 0.05)\n",
        "\n",
        "# Define the parameter grid using the generated learning rates\n",
        "param_grid = {'classifier__learning_rate': learning_rates}\n",
        "\n",
        "# Set up the Gradient Boosting Classifier with fixed number of estimators\n",
        "gbd_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create the pipeline\n",
        "gbd_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('classifier', gbd_model)\n",
        "])\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(gbd_pipeline, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to find the best learning rate\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best learning rate and its corresponding accuracy\n",
        "best_learning_rate = grid_search.best_params_['classifier__learning_rate']\n",
        "best_model = grid_search.best_estimator_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "# Print the best learning rate and its corresponding accuracy\n",
        "print(\"Best Learning Rate:\", best_learning_rate)\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "y_pred_gbd = best_model.predict(X_test)\n",
        "\n",
        "# Calculate confusion matrix for the best model\n",
        "conf_matrix_best = confusion_matrix(y_test, y_pred_gbd)\n",
        "\n",
        "# Calculate classification report for the best model\n",
        "cls_report_best = classification_report(y_test, y_pred_gbd)\n",
        "\n",
        "# Calculate ROC curve for the best model\n",
        "fpr_best, tpr_best, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# Store the results in the lists\n",
        "accuracy.append(best_accuracy)\n",
        "confusion_matrices.append(conf_matrix_best)\n",
        "classification_reports.append(cls_report_best)\n",
        "roc_curves.append((fpr_best, tpr_best))\n",
        "\n",
        "# Print the results for the best model\n",
        "print(\"Accuracy:\", best_accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
        "print(\"Classification Report:\\n\", cls_report_best)"
      ],
      "metadata": {
        "id": "jI6PIKO7Wgr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM model with RBF kernel\n",
        "svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
        "\n",
        "# Create a pipeline that includes scaling, imputation, and the SVM classifier\n",
        "svm_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),  # SVMs require feature scaling for optimal performance\n",
        "    ('classifier', svm_model)\n",
        "])\n",
        "\n",
        "# Fit the SVM model\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_svm = svm_pipeline.predict(X_test)\n",
        "\n",
        "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "confusion_matrices.append(cm_svm)\n",
        "\n",
        "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_pipeline.decision_function(X_test))\n",
        "roc_curves.append((fpr_svm, tpr_svm))\n",
        "\n",
        "# Calculate accuracy and append it to the list\n",
        "accuracy.append(accuracy_score(y_test, y_pred_svm))\n",
        "\n",
        "# Calculate classification report and append it to the list\n",
        "cls_report_svm = classification_report(y_test, y_pred_svm)\n",
        "classification_reports.append(cls_report_svm)\n",
        "\n",
        "# Print the accuracy and a classification report to see performance details\n",
        "print(\"Accuracy (SVM):\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Confusion Matrix (SVM):\\n\", confusion_matrix(y_test, y_pred_svm))\n",
        "print(\"Classification Report (SVM):\\n\", classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "id": "u6OdmBSSWguO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline for preprocessing\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Apply transformations and prepare data\n",
        "X_train_prepared = pipeline.fit_transform(X_train)\n",
        "X_test_prepared = pipeline.transform(X_test)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_prepared.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Use sigmoid for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define a callback to record training metrics\n",
        "class MetricsCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy.append(logs['accuracy'])\n",
        "\n",
        "# Fit the neural network\n",
        "history = model.fit(X_train_prepared, y_train, epochs=50, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_prepared, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Retrieve the confusion matrix and ROC curve from the neural network's predictions\n",
        "y_pred_nn = (model.predict(X_test_prepared) > 0.5).astype(\"int32\")\n",
        "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
        "confusion_matrices.append(cm_nn)\n",
        "\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, model.predict(X_test_prepared))\n",
        "roc_curves.append((fpr_nn, tpr_nn))"
      ],
      "metadata": {
        "id": "HtuXyiMEWgws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, title):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, cmap=\"Blues\")\n",
        "    plt.ylabel('Actual label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "model_names = [\"Random Forest\", \"Logistic Regression\", \"Gradient Boosting static\", \"Gradient Boosting dynamic\", \"Support Vector Machine\", \"Neural Network\"]\n",
        "for idx, (cm, model_name) in enumerate(zip(confusion_matrices, model_names)):\n",
        "    plot_confusion_matrix(cm, f'Confusion Matrix - {model_name}')"
      ],
      "metadata": {
        "id": "HOhSFNvuWgzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, (curve, model_name) in enumerate(zip(roc_curves, model_names)):\n",
        "    fpr, tpr = curve\n",
        "    auc_score = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AwUpECsHXAY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect accuracies for each model\n",
        "accuracies = [accuracy_score(y_test, y_pred_rf),\n",
        "              accuracy_score(y_test, y_pred_lr),\n",
        "              accuracy_score(y_test, y_pred_gbs),\n",
        "              accuracy_score(y_test, y_pred_gbd),\n",
        "              accuracy_score(y_test, y_pred_svm),\n",
        "              accuracy_score(y_test, y_pred_nn)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=model_names, y=accuracies, hue=model_names, palette='deep', legend=False)\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylim(0, 1)  # Set y-axis limits to show percentages from 0 to 100%\n",
        "plt.xticks(rotation=60)  # Rotate x-axis labels\n",
        "plt.legend([], frameon=False)  # Hides the legend\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L762uJvSXAcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwnNd3MqXAfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}